train:
  num_gpus: 1
  num_nodes: 1
  validation_interval: 1
  optim:
    lr_backbone: 2e-05
    lr: 0.0002
    lr_steps: [10, 20]
    momentum: 0.9
  num_epochs: 1
  freeze: ["backbone", "bert"]
  pretrained_model_path: /workspace/tao-experiments/mask_grounding_dino/grounding_dino_vgrounding_dino_swin_tiny_commercial_trainable_v1.0/grounding_dino_swin_tiny_commercial_trainable.pth
  precision: bf16
  activation_checkpoint: True
dataset:
  train_data_sources:
    - image_dir: /data/raw-data/val2017/
      json_file: /data/odvg/annotations/instances_val2017_odvg.jsonl
      label_map: /data/odvg/annotations/instances_val2017_odvg_labelmap.json
  val_data_sources:
    image_dir: /data/raw-data/val2017/
    json_file: /data/odvg/annotations/instances_val2017_remapped.json
  max_labels: 80
  batch_size: 4
  workers: 8
model:
  backbone: swin_tiny_224_1k
  num_feature_levels: 4
  dec_layers: 6
  enc_layers: 6
  num_queries: 900
  dropout_ratio: 0.0
  dim_feedforward: 2048
  loss_types: ['labels', 'boxes', 'masks']
  log_scale: auto
  class_embed_bias: True
